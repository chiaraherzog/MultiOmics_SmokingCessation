---
title: "Variance decomposition"
format:
  html:
    toc: true
    code-fold: true
    code-overflow: wrap
    code-tools: true
---

```{r setup, include=T}
knitr::opts_chunk$set(echo = T, message = F, warning = F, eval = F)
```


```{r libs, eval = F}
library(dplyr)
library(here)
library(ggplot2)
library(MultiAssayExperiment)
library(lme4)
library(insight)
here::i_am("helper-variance-decomposition.qmd")
```

Here, we partition variance of omic features.

* lower-level ASVs included.
* zero inflation considered for the microbiome, thus ASVs will be CLR transformed.

## Preparing the data

First, we load and prepare the normalized data:

```{r, eval = F}
load("data/data_normalized.Rdata")
# Extract relevant omic and covariate data:
load(here("src/vars.Rdata"))

vars_list <- vars |> 
  dplyr::filter(!grepl("ASVs$|families_clr|Immune", assay)) |> 
  dplyr::select(assay, x) |> 
  dplyr::group_by(assay) |> 
  dplyr::summarise(features = list(x), .groups = 'drop') |> 
  tibble::deframe()

data <- subsetByAssay(data, vars_list)

df <- longForm(data[,data$interventionId == "S" & !data$visitId %in% c("M12", "M18"),],
                 colDataCols=c("subjectId", "visitId",
                               "age_at_consent", "compliance",
                               "smoking_py")) |>
  as.data.frame()

rm(data);gc()
```

Tidy up factor data:

```{r, eval = F}
df$visitId <- factor(as.character(df$visitId), levels = c("M0", "M2", "M4", "M6"))
df$compliance <- factor(df$compliance, levels = c("lower compliance",  "higher compliance"))
df$subjectId <- factor(df$subjectId)
df <- df[!is.na(df$value),]
```

Code unique feature ids by concatenating the assay and feature name:

```{r}
# feature IDs
df$featureid <- paste0(df$assay,"_",df$rowname)
featureid <- unique(df$featureid)
```

Counting the number of features and number of unique subject to filter featureids that have too few observations:

```{r, eval = F}
counts <- df |> 
  as.data.frame() |> 
  dplyr::group_by(featureid) |> 
  dplyr::reframe(n = dplyr::n(),
                 n_id = length(unique(subjectId))) |> 
  dplyr::ungroup() |> 
  dplyr::mutate(ratio = n/n_id) |> 
  dplyr::filter(ratio > 1.2)
featureid <- featureid[featureid %in% counts$featureid]
```

## LMMs for variance decomposition

The below code is parallelized and takes approximately ~3.5s for 400 features.

```{r, eval = F}
out.lmm <- parallel::mclapply(featureid, function(i) {
  tryCatch(lmer(value ~ visitId*compliance + age_at_consent + smoking_py + (1 | subjectId),
                data = as.data.frame(df[df$featureid==i,]),
                REML = F),
           error = function(e) return(e))
}, mc.preschedule = T, mc.cores = 1)
names(out.lmm) <- featureid
save(out.lmm, file = "out/variance_partition_lmm_revised.Rdata") # save intermediate out.lmm (optional)
```


## Extracting the variance from models

```{r, eval = F}
out.lmm <- get(load("out/variance_partition_lmm_revised.Rdata"))

# Extract variance
df.var <- dplyr::bind_rows(lapply(out.lmm, function(x) as.data.frame(insight::get_variance(x))), .id="featureid")
save(df.var, file = "out/variance_partition_var_revised.Rdata")
```

```{r}
df.var <- get(load("out/variance_partition_var_revised.Rdata"))
check <- df.var |> 
  dplyr::mutate(featureid =  gsub("_clr_",".clr_",featureid)) |> 
  dplyr::mutate(ome = gsub("_.*","",featureid)) |> 
  dplyr::filter(is.na(var.random))
table(check$ome)
```

```{r}
df.var$f.var.fixed <- df.var$var.fixed/(df.var$var.fixed + df.var$var.random + df.var$var.residual)
df.var$f.var.random <- df.var$var.random/(df.var$var.fixed + df.var$var.random + df.var$var.residual)
df.var$f.var.residual <- df.var$var.residual/(df.var$var.fixed + df.var$var.random + df.var$var.residual)
# Assay group
df.var <- df.var |>
  # reframe
  dplyr::select(featureid, starts_with("f.var")) |>
  dplyr::mutate(featureid =  gsub("_clr_",".clr_",featureid)) %>%
  dplyr::mutate(assay = stringr::str_split(featureid, "_", simplify = T)[,1]) |>
  dplyr::rowwise() |> 
  dplyr::mutate(icc = f.var.random/sum(f.var.random+f.var.fixed+f.var.residual)) |> 
  dplyr::ungroup()
save(df.var, file = "out/variance_partition_df_var_revised.Rdata")
```


ICC is computed as V ran/V total and visualised for each ome in [Figure 1](fig1-overview.qmd).